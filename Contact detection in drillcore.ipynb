{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact detection in drillcore (inspired by June et al. 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import random as rd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "from skimage.color import rgb2grey, rgb2hsv\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with one contact and try to see what works better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im1 = np.array(Image.open(r'LEM-37\\Export_10cm_slices\\245.2m-LEM-37.jpg'))\n",
    "im2 = np.array(Image.open(r'LEM-37\\Export_10cm_slices\\251.1m-LEM-37.jpg'))\n",
    "im = np.concatenate((im1, im2), axis=0)\n",
    "im = im[:, 150:500, :]\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(im1[:1000, 150:500, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "im = rgb2grey(im)\n",
    "mean_value = np.mean(im, axis=1)\n",
    "mean_df = pd.DataFrame(mean_value, columns=['mean'])\n",
    "#mean_df['mean'] = mean_value\n",
    "mean_df['1cm'] = mean_df['mean'].rolling(window=100, min_periods=0, center=True).mean()\n",
    "mean_df['10cm'] = mean_df['mean'].rolling(window=1000, min_periods=0, center=True).mean()\n",
    "mean_df['100cm'] = mean_df['mean'].rolling(window=10000, min_periods=0, center=True).mean()\n",
    "mean_df['500cm'] = mean_df['mean'].rolling(window=50000, min_periods=0, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(5, 6))\n",
    "axes[0].plot(mean_df['mean'], mean_df.index.values/100, linestyle='-')\n",
    "axes[1].plot(mean_df['1cm'], mean_df.index.values/100, linestyle='-')\n",
    "axes[2].plot(mean_df['10cm'], mean_df.index.values/100, linestyle='-')\n",
    "axes[3].plot(mean_df['100cm'], mean_df.index.values/100, linestyle='-')\n",
    "axes[4].plot(mean_df['500cm'], mean_df.index.values/100, linestyle='-')\n",
    "for i in range(len(axes)):\n",
    "    axes[i].invert_yaxis()\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "for i in range(len(axes)-1):    \n",
    "    axes[i+1].get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_df['10cm_var'] = mean_df['mean'].rolling(window=1000, min_periods=0, center=True).std()\n",
    "mean_df['100cm_var'] = mean_df['mean'].rolling(window=10000, min_periods=0, center=True).std()\n",
    "mean_df['500cm_var'] = mean_df['mean'].rolling(window=50000, min_periods=0, center=True).std()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(6, 6))\n",
    "axes[0].plot(mean_df['mean'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[1].plot(mean_df['10cm_var'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[2].plot(mean_df['100cm_var'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[3].plot(mean_df['500cm_var'], mean_df.index.values / 100, linestyle='-')\n",
    "for i in range(len(axes)):\n",
    "    axes[i].invert_yaxis()\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "for i in range(len(axes) - 1):    \n",
    "    axes[i + 1].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wp = pywt.WaveletPacket(data=mean_df['mean'], wavelet='db1', mode='symmetric', maxlevel=5)\n",
    "fig = plt.figure()\n",
    "plt.set_cmap('bone')\n",
    "ax = fig.add_subplot(wp.maxlevel + 1, 1, 1)\n",
    "ax.plot(mean_df['mean'], 'k')\n",
    "ax.set_xlim(0, len(mean_df['mean'] - 1))\n",
    "ax.set_title(\"Wavelet packet coefficients\")\n",
    "\n",
    "for level in range(1, wp.maxlevel + 1):\n",
    "    ax = fig.add_subplot(wp.maxlevel + 1, 1, level + 1)\n",
    "    nodes = wp.get_level(level, \"freq\")\n",
    "    nodes.reverse()\n",
    "    labels = [n.path for n in nodes]\n",
    "    values = -abs(np.array([n.data for n in nodes]))\n",
    "    ax.imshow(values, interpolation='nearest', aspect='auto')\n",
    "    ax.set_yticks(np.arange(len(labels) - 0.5, -0.5, -1), labels)\n",
    "    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wp = pywt.WaveletPacket(data=mean_df['mean'], wavelet='db1', mode='symmetric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wp.maxlevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Gaussian wavelet and its derivative (Mexican Hat wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef, freqs = pywt.cwt(data=mean_df['mean'], scales=np.arange(1, 200), wavelet='gaus1')\n",
    "coef = np.rot90(coef, 3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 6))\n",
    "axes[0].plot(mean_df['mean'], mean_df.index.values/100, linestyle='-')\n",
    "axes[1].plot(coef[:, 5], range(len(coef[:, 5])), linestyle='-')\n",
    "axes[2].plot(coef[:, 10], range(len(coef[:, 10])), linestyle='-')\n",
    "axes[3].matshow(coef, cmap='inferno', extent = (0, 25000, 0, len(mean_df['mean'])))\n",
    "for i in range(len(axes) - 1):\n",
    "    axes[i].set_ylim([0,axes[i].lines[0].get_ydata().max()])\n",
    "    axes[i+1].get_yaxis().set_visible(False)\n",
    "for i in range(len(axes)):\n",
    "    axes[i].invert_yaxis()\n",
    "    axes[i].get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef, freqs = pywt.cwt(data=mean_df['mean'], scales=np.arange(1,200), wavelet='mexh')\n",
    "coef = np.rot90(coef, 3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(6, 6))\n",
    "axes[0].plot(mean_df['mean'], mean_df.index.values/100, linestyle='-')\n",
    "axes[1].plot(coef[:, 5], range(len(coef[:, 5])), linestyle='-')\n",
    "axes[2].plot(coef[:, 10], range(len(coef[:, 10])), linestyle='-')\n",
    "axes[3].matshow(coef, cmap='inferno', extent = (0, 20000, 0, len(mean_df['mean'])))\n",
    "for i in range(len(axes)-1):\n",
    "    axes[i].set_ylim([0,axes[i].lines[0].get_ydata().max()])\n",
    "    axes[i+1].get_yaxis().set_visible(False)\n",
    "for i in range(len(axes)):\n",
    "    axes[i].invert_yaxis()\n",
    "    axes[i].get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(512)\n",
    "y = np.sin(2*np.pi*x/32)\n",
    "coef, freqs=pywt.cwt(y,np.arange(1,129),'gaus1')\n",
    "plt.matshow(coef) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire LEM-18 drillhole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get geological log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_litho_grid(From, To, Litho, step):\n",
    "    ###### using data to make an empty numpy array\n",
    "    length = (np.max(To) - np.min(From)) / step\n",
    "    grid = np.zeros(shape=(int(length), 1))\n",
    "    ##### transformation of litho names into numbers\n",
    "    Litho = Litho.replace(to_replace=Litho.unique(), value=np.arange(1, len(Litho.unique()) + 1, 1), inplace=False)\n",
    "    ##### combining log data arrays into single dataframe\n",
    "    log_litho = pd.concat((From, To, Litho), axis=1)\n",
    "    log_litho.columns = ['From', 'To', 'Litho']\n",
    "    for i in range(int(length)):\n",
    "        depth_step = np.min(From) + i * step\n",
    "        litho_step = log_litho.loc[(log_litho['From'] < depth_step) & (log_litho['To'] >= depth_step), ['Litho']]\n",
    "        if litho_step.empty:\n",
    "            grid[i, :] = np.nan\n",
    "        else:\n",
    "            litho_step = litho_step.iloc[0, 0]\n",
    "            grid[i, :] = litho_step\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_set = pd.read_csv('LEM-18\\Geological_log_LEM-18.csv', sep=';')\n",
    "litho_colors = ['#000000', '#0066ff', '#ffff00','#663300','#ff9900']\n",
    "cmap_litho = colors.ListedColormap(litho_colors[0:len(litho_colors)], 'indexed')\n",
    "grid = make_litho_grid(class_set['from'], class_set['to'], class_set['litho_simplified'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get concatenated image mean (width of image averaged into one pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenating image without applying mean\n",
    "raise DeprecationWarning('Unefficient.')\n",
    "\n",
    "onlyfiles = listdir('LEM-18\\Export_10cm_slices')\n",
    "# images_list, xml_list = onlyfiles[::2], onlyfiles[1::2]\n",
    "\n",
    "# print(\"Total length:\", len(onlyfiles))\n",
    "\n",
    "concat = np.empty([1000 * len(onlyfiles), 50, 3], dtype=np.int16)\n",
    "# concat = np.empty([1000 * 600, 50, 3])\n",
    "\n",
    "for i, image in enumerate(onlyfiles):\n",
    "    im = np.array(Image.open('LEM-18/Export_10cm_slices/' + image))\n",
    "    im = im[:, 150:500, :]\n",
    "    concat[i * 1000:(i + 1) * 1000] = im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting to another color format\n",
    "raise DeprecationWarning('Unefficient.')\n",
    "\n",
    "im = np.empty([concat.shape[0], concat.shape[1]], np.float16)\n",
    "batch = 10000\n",
    "convert = rgb2grey  # rgb2grey or rgb2hsv\n",
    "\n",
    "for i in range(concat.shape[0] // batch):  # Processing the whole file at once resulted in MemoryError.\n",
    "    im[i * batch:(i + 1) * batch] = convert(concat[i * batch:(i + 1) * batch])  # [:, :, 2].reshape([-1, concat.shape[1]])\n",
    "\n",
    "im[concat.shape[0] // batch * batch:] = convert(concat[concat.shape[0] // batch * batch:])  # [:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filtering using wavelets and applying mean\n",
    "raise DeprecationWarning('Unefficient.')\n",
    "\n",
    "level = None  # Setting *level* to None is equivalent to setting *level* to the max level.\n",
    "              # Data needs to be further filtered if the max level is low, or else computation will be excessively slow.\n",
    "\n",
    "coefs = pywt.wavedec2(im, 'mexh', level=level)\n",
    "im = pywt.waverec2((coefs[0],), 'db1')\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(1, 20))\n",
    "# axes.imshow(concat, interpolation='none', aspect='auto')\n",
    "# axes.imshow(im, interpolation='none', aspect='auto')\n",
    "im = np.mean(im, axis=1).reshape([-1, 1])\n",
    "axes.imshow(im, interpolation='none', aspect='auto', cmap=mpl.cm.gray)\n",
    "\n",
    "plt.show()\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concatenate image while converting and applying mean\n",
    "\n",
    "onlyfiles = listdir('LEM-37\\Export_10cm_slices')\n",
    "\n",
    "im = np.empty([1000 * len(onlyfiles), 1], dtype=np.float32)\n",
    "\n",
    "for i, image in enumerate(onlyfiles):\n",
    "    temp = np.array(Image.open('LEM-37/Export_10cm_slices/' + image))\n",
    "    temp = temp[:, 150:500, :]\n",
    "    temp = rgb2grey(temp)\n",
    "    temp = np.mean(temp, axis=1).reshape([-1, 1])\n",
    "    im[i * 1000:(i + 1) * 1000] = temp\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(1, 20))\n",
    "axes.imshow(im, interpolation='none', aspect='auto', cmap=mpl.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(mean_array, columns=['mean'])\n",
    "# mean_df['mean'] = mean_value\n",
    "mean_df['1cm']   = mean_df['mean'].rolling(window=100,   min_periods=0, center=True).mean()\n",
    "mean_df['10cm']  = mean_df['mean'].rolling(window=1000,  min_periods=0, center=True).mean()\n",
    "mean_df['100cm'] = mean_df['mean'].rolling(window=10000, min_periods=0, center=True).mean()\n",
    "mean_df['500cm'] = mean_df['mean'].rolling(window=50000, min_periods=0, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 6, figsize=(5, 6))\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "axes[1].plot(mean_df['mean'],  mean_df.index.values / 100, linestyle='-')\n",
    "axes[2].plot(mean_df['1cm'],   mean_df.index.values / 100, linestyle='-')\n",
    "axes[3].plot(mean_df['10cm'],  mean_df.index.values / 100, linestyle='-')\n",
    "axes[4].plot(mean_df['100cm'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[5].plot(mean_df['500cm'], mean_df.index.values / 100, linestyle='-')\n",
    "for i in range(len(axes)-1):\n",
    "    axes[i + 1].set_ylim([0,axes[i + 1].lines[0].get_ydata().max()])\n",
    "    axes[i + 1].get_yaxis().set_visible(False)\n",
    "    # axes[i+1].invert_yaxis()\n",
    "for i in range(len(axes)):\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes = [5, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "\n",
    "wp = pywt.WaveletPacket(data=mean_df['mean'], wavelet='db1', mode='symmetric')\n",
    "\n",
    "fig, axes = plt.subplots(1, len(indexes) + 3, figsize=(10, 6))\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "axes[1].plot(mean_df['mean'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[2].plot(mean_df['500cm'], mean_df.index.values / 100, linestyle='-')\n",
    "for n, i in enumerate(indexes):\n",
    "    axes[n + 3].plot(wp['a' * i].data, range(len(wp['a' * i].data)), linestyle='-')\n",
    "for i in range(len(axes) - 1):\n",
    "    axes[i+1].set_ylim([0,axes[i + 1].lines[0].get_ydata().max()])\n",
    "    axes[i+1].get_yaxis().set_visible(False)\n",
    "    # axes[i+1].invert_yaxis()\n",
    "for i in range(len(axes)):\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes = [0, 4, 8, 12, 17, 18, 19, 20]\n",
    "\n",
    "wp = pywt.WaveletPacket(data=mean_df['mean'], wavelet='db1', mode='symmetric')\n",
    "\n",
    "fig, axes = plt.subplots(1, len(indexes) + 3, figsize=(10, 6))\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "axes[1].plot(mean_df['mean'], mean_df.index.values / 100, linestyle='-')\n",
    "axes[2].plot(mean_df['500cm'], mean_df.index.values / 100, linestyle='-')\n",
    "for n, i in enumerate(indexes):\n",
    "    axes[n + 3].plot(wp['a' * i + 'd'].data, range(len(wp['a' * i + 'd'].data)), linestyle='-')\n",
    "for i in range(len(axes) - 1):\n",
    "    axes[i + 1].set_ylim([0,axes[i + 1].lines[0].get_ydata().max()])\n",
    "    axes[i + 1].get_yaxis().set_visible(False)\n",
    "    # axes[i + 1].invert_yaxis()\n",
    "for i in range(len(axes)):\n",
    "    axes[i].get_xaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiscale hierarchical domaining using continuous wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Padding to avoid border effects (optional)\n",
    "\n",
    "# PARAMETERS #\n",
    "pad_fraction = .2  # .1 is sufficient\n",
    "##############\n",
    "\n",
    "im = im.reshape([-1])\n",
    "pad = int(pad_fraction * im.shape[0])\n",
    "im = np.hstack([im[pad:0:-1], im, im[-2:-pad - 2:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous wavelets\n",
    "\n",
    "# scales = np.logspace(1, 3.5, 10)\n",
    "scales = np.logspace(2., 3., 5)\n",
    "\n",
    "# print(pywt.wavelist(kind='continuous'))\n",
    "\n",
    "coefs = pywt.cwt(data=im, scales=scales, wavelet='mexh')\n",
    "coefs = np.swapaxes(coefs[0], 0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unpad\n",
    "\n",
    "im = im[pad:-pad]\n",
    "pad = int(pad_fraction * coefs.shape[0] /(1+pad_fraction*2))\n",
    "coefs = coefs[pad:-pad]\n",
    "\n",
    "coef_max = np.amax(coefs)\n",
    "coefs = coefs / coef_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(3, 100))\n",
    "\n",
    "coef_max = np.amax(coefs)\n",
    "axes.imshow(coefs, interpolation='nearest', aspect='auto', cmap=mpl.cm.bwr, vmin=-coef_max, vmax=coef_max)\n",
    "cont = axes.contour(coefs, levels=[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tessellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PARAMETERS #\n",
    "# Children with intensities smaller than filter_threshold are merged (default: 0.15):\n",
    "filter_threshold = .15\n",
    "# Accelerates computation by reducing the initial quantity of rectangles (default: 0):\n",
    "min_width_filter = 3\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rectangles from contours\n",
    "\n",
    "paths = cont.collections[0].get_paths()\n",
    "rectangles = np.empty([len(paths), 4], dtype = np.int32)\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    v = path.vertices\n",
    "    x = v[:, 0]\n",
    "    y = v[:, 1]\n",
    "    if y[0] > y[-1]:\n",
    "        y[0], y[-1] = y[-1], y[0]\n",
    "    rectangles[i] = [np.amin(x), y[0], np.amax(x), y[-1] - y[0]]  # ['x', 'y', 'width', 'height']\n",
    "\n",
    "rectangles = rectangles[(rectangles[:, 0] == 0) & (rectangles[:, 2] != 0) & (rectangles[:, 3] != 0)]\n",
    "rectangles = rectangles[rectangles[:, 2] > min_width_filter]\n",
    "rectangles = np.vstack([[0, 0, coefs.shape[1] - 1, coefs.shape[0] - 1], rectangles])\n",
    "\n",
    "del paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete overlapping rectangles  # SLOW\n",
    "\n",
    "bool_ = np.ones(rectangles.shape[0], dtype=bool)\n",
    "\n",
    "for i1, r1 in enumerate(rectangles):\n",
    "\n",
    "    for i2, r2 in enumerate(rectangles):\n",
    "\n",
    "        if r2[2] > r1[2] or i1 == i2 or not bool_[i2]:\n",
    "            continue\n",
    "\n",
    "        upper_in = r2[1] >= r1[1] and r2[1] < r1[1] + r1[3]\n",
    "        bottom_in = r2[1] + r2[3] > r1[1] and r2[1] + r2[3] <= r1[1] + r1[3]\n",
    "\n",
    "        if upper_in != bottom_in:\n",
    "            bool_[i2] = False\n",
    "\n",
    "rectangles = rectangles[bool_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filtering the rectangles\n",
    "# If a rectangle does not contain an abs(value) greater than filter_threshold, it is deleted.\n",
    "\n",
    "bool_ = np.ones(rectangles.shape[0], dtype=bool)\n",
    "\n",
    "for i, r in enumerate(rectangles):\n",
    "    if not (np.absolute(coefs[r[1]:r[1] + r[3] + 1, r[0]:r[0] + r[2] + 1]) > filter_threshold * coef_max).any():\n",
    "        bool_[i] = False\n",
    "\n",
    "shape_ = rectangles.shape[0]\n",
    "rectangles = rectangles[bool_]\n",
    "rect_backup = np.copy(rectangles)\n",
    "print(\"Rectangles left:\", rectangles.shape[0], '/', shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Restore rectangles array\n",
    "\n",
    "rectangles = rect_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create new rectangles for every child\n",
    "\n",
    "import time\n",
    "now = time.time()\n",
    "\n",
    "flag = True\n",
    "ver_rect = []  # Added vertical rectangles, the parents\n",
    "non_parents = np.zeros(rectangles.shape[0], dtype=bool)  # Array which increase computation effectiveness\n",
    "temp = np.copy(rectangles)  # The set of children doesn't need to be modified, as new children won't be wider than the\n",
    "                            # original children and as parents' max_x remain at their original width.\n",
    "                            # Also note that temp[n, 0] + temp [n, 2] == temp[n, 2] for every n, as temp[n, 0] == 0.\n",
    "\n",
    "while flag:  # While there are still horizontal rectangles that are added\n",
    "    flag = False\n",
    "    bool_ = np.ones(rectangles.shape[0], dtype=bool)  # Keeps track of elements to delete after the loops\n",
    "    hor_rect = []  # Added horizontal rectangles, the children\n",
    "\n",
    "    for i1, r1 in enumerate(rectangles):\n",
    "        if non_parents[i1]:  # If the rectangle does not have any child\n",
    "            continue\n",
    "\n",
    "        children = []\n",
    "\n",
    "        for i2, r2 in enumerate(temp):\n",
    "\n",
    "            if r2[1] >= r1[1] and r2[1] < r1[1] + r1[3] and r2[3] < r1[3] and r2[2] <= r1[2]:\n",
    "                if not (r1 == r2).all():  # Time consuming, add unique_id?\n",
    "                    children.append(i2)  # r2 is a children\n",
    "\n",
    "        if len(children) == 0:  # If there is no children\n",
    "            non_parents[i1] = True\n",
    "            continue\n",
    "\n",
    "        upper_x = [temp[i][2] for i in children]\n",
    "        max_x = max(upper_x)\n",
    "\n",
    "        children = [temp[i] for i, j in zip(children, upper_x) if j == max_x]  # Gets the eldest children\n",
    "        children.sort(key=lambda x: x[1])\n",
    "\n",
    "        if r1[2] - max_x != 0:\n",
    "            ver_rect += [(max_x, r1[1], r1[2] - max_x, r1[3])]\n",
    "        bool_[i1] = False\n",
    "\n",
    "        children = np.vstack([np.array([[0, r1[1], max_x, 0]]),\n",
    "                              *children,\n",
    "                              np.array([[0, r1[1] + r1[3], max_x, 0]])])  # Add borders\n",
    "\n",
    "        for top, bottom in zip(children[:-1], children[1:]):  # Adds a rectangle between each pair of children\n",
    "            if bottom[1] - top[1] - top[3] != 0:\n",
    "                hor_rect += [(0, top[1] + top[3], max_x, bottom[1] - top[1] - top[3])]\n",
    "                flag = True\n",
    "\n",
    "    rectangles = rectangles[bool_]\n",
    "    rectangles = np.vstack([rectangles, *hor_rect])  # The new children could be parents; those must be iterated over\n",
    "\n",
    "    non_parents = non_parents[bool_]\n",
    "    non_parents = np.hstack([non_parents, np.zeros(len(hor_rect), dtype=bool)])  # Must remain the same length as rectangles\n",
    "\n",
    "    prec, now = now, time.time()\n",
    "    print('Time elapsed:      ', int(now - prec), 'seconds')\n",
    "    print('ver_rect length:   ', len(ver_rect))\n",
    "    print('rectangles length: ', rectangles.shape[0])\n",
    "    print('hor_rect length:   ', len(hor_rect), '\\n')\n",
    "\n",
    "rectangles = np.vstack([rectangles, *ver_rect])\n",
    "\n",
    "del non_parents, ver_rect, hor_rect, bool_, temp\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot rectangles\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(3, 200))\n",
    "\n",
    "axes.imshow(coefs, interpolation='nearest', aspect='auto', cmap=mpl.cm.bwr, vmin=-coef_max, vmax=coef_max)\n",
    "\n",
    "p = mpl.collections.PatchCollection([mpl.patches.Rectangle((r[0], r[1]), r[2], r[3]) for r in rectangles])\n",
    "p.set_facecolor('none')\n",
    "p.set_edgecolor('k')\n",
    "axes.add_collection(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geological log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Color rectangles\n",
    "\n",
    "value = np.zeros(rectangles.shape[0])\n",
    "\n",
    "for i, r in enumerate(rectangles):\n",
    "    array_ = coefs[r[1]:r[1] + r[3] + 1, r[0]:r[0] + r[2] + 1]\n",
    "    extremums = (np.amin(array_), np.amax(array_))\n",
    "\n",
    "    if -extremums[0] > extremums[1]:\n",
    "        value[i] = extremums[0]\n",
    "    else:\n",
    "        value[i] = extremums[1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(3, 200))\n",
    "\n",
    "axes.axis([0, coefs.shape[1] - 1, 0, coefs.shape[0] - 1])\n",
    "axes.invert_yaxis()\n",
    "\n",
    "p = mpl.collections.PatchCollection([mpl.patches.Rectangle((r[0], r[1]), r[2], r[3]) for r in rectangles], cmap=mpl.cm.bwr)\n",
    "p.set_clim([-coef_max, coef_max])\n",
    "p.set_array(value)\n",
    "p.set_edgecolor('k')\n",
    "axes.add_collection(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot with geological log\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 60))\n",
    "\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "\n",
    "axes[1].imshow(coefs, interpolation='nearest', aspect='auto', cmap=mpl.cm.bwr, vmin=-coef_max, vmax=coef_max)\n",
    "\n",
    "p = mpl.collections.PatchCollection([mpl.patches.Rectangle((r[0], r[1]), r[2], r[3]) for r in rectangles], cmap=mpl.cm.bwr)\n",
    "p.set_clim([-coef_max, coef_max])\n",
    "p.set_array(value)\n",
    "p.set_edgecolor('k')\n",
    "p.set_alpha(0.5)\n",
    "axes[1].add_collection(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get boundaries intersecting the x == slice_ axis.\n",
    "\n",
    "slice_ = 25\n",
    "\n",
    "boundaries = rectangles[(rectangles[:, 0] <= slice_) & (slice_ < rectangles[:, 0] + rectangles[:, 2])][:, 1]\n",
    "boundaries.sort()\n",
    "print(list(boundaries) + [coefs.shape[0]])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 60))\n",
    "\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "\n",
    "axes[1].imshow(coefs, interpolation='nearest', aspect='auto', cmap=mpl.cm.bwr, vmin=-coef_max, vmax=coef_max)\n",
    "\n",
    "lines = [[(0, b), (coefs.shape[1] - 1, b)] for b in boundaries]\n",
    "p = mpl.collections.LineCollection(lines)\n",
    "p.set_color('k')\n",
    "axes[1].add_collection(p)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get boundaries intersecting the x == slice_ axis.\n",
    "\n",
    "slice_frac = .5\n",
    "slice_ = int(coefs.shape[1] * slice_frac)\n",
    "\n",
    "# boundaries = rectangles[(rectangles[:, 0] <= slice_) & (slice_ < rectangles[:, 0] + rectangles[:, 2])][:, 1]\n",
    "# boundaries.sort()\n",
    "# print(list(boundaries) + [coefs.shape[0]])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 60))\n",
    "\n",
    "axes[0].imshow(grid, interpolation='none', aspect='auto', cmap=cmap_litho, vmin=1, vmax=len(litho_colors))\n",
    "\n",
    "# axes[1].imshow(coefs, interpolation='nearest', aspect='auto', cmap=mpl.cm.bwr, vmin=-coef_max, vmax=coef_max)\n",
    "\n",
    "boundaries = (abs(coefs[:, slice_]) < 1e-3).astype(int).reshape([-1, 1])\n",
    "\n",
    "axes[1].imshow(boundaries, interpolation='none', aspect='auto', cmap=mpl.cm.binary, vmin=0, vmax=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
